[General]
version = 0.1.0
first_run = true

[AI]
# Online API mode - no local models needed
use_online_api = true
max_tokens = 512
temperature = 0.7

[API]
# Provider priority: groq (primary), openrouter (fallback)
provider = auto  # groq, openrouter, or auto (tries groq first, then openrouter)
# Groq models (fast, 1K RPM) - Updated December 2024
groq_model = llama-3.3-70b-versatile
groq_fallback_model = llama-3.1-8b-instant
# OpenRouter free models (fallback)
openrouter_model = meta-llama/llama-3.2-3b-instruct:free
openrouter_fallback_model = qwen/qwen-2.5-72b-instruct:free
# Context settings
max_context_messages = 50
enable_web_search = true
# Request settings
timeout = 30

[GUI]
hotkey = Super+Shift
sidebar_width = 400
sidebar_animation_speed = 200
theme = cosmic-dark

[Automation]
click_delay = 0.1
type_delay = 0.05
screenshot_on_error = true
max_retries = 3

[Permissions]
allow_file_operations = true
allow_network_access = true  
allow_system_settings = false
require_confirmation = true

[Development]
hot_reload = false
debug_mode = false
log_level = INFO

