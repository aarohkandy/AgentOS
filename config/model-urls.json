{
    "version": "2.0.0",
    "updated": "2024-12-27",
    "base_url": "https://huggingface.co",
    
    "tiers": {
        "1": {
            "name": "EXTREME Easy",
            "description": "For systems with <1GB RAM - ultra-tiny model",
            "recommended_models": ["qwen2.5-0.5b"],
            "default": "qwen2.5-0.5b",
            "models": {
                "qwen2.5-0.5b": {
                    "name": "Qwen 2.5 0.5B Instruct",
                    "size_gb": 0.4,
                    "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 32768,
                    "note": "If URL fails, use: https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF"
                }
            }
        },
        "2": {
            "name": "Low",
            "description": "For systems with 2-4GB RAM - edge-ready",
            "recommended_models": ["llama3.2-3b"],
            "default": "llama3.2-3b",
            "models": {
                "llama3.2-3b": {
                    "name": "Llama 3.2 3B Instruct",
                    "size_gb": 2.0,
                    "url": "https://huggingface.co/TheBloke/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                }
            }
        },
        "3": {
            "name": "Medium",
            "description": "For systems with 16-32GB RAM or 8-12GB VRAM",
            "recommended_models": ["llama3.1-8b"],
            "default": "llama3.1-8b",
            "models": {
                "llama3.1-8b": {
                    "name": "Llama 3.1 8B Instruct",
                    "size_gb": 4.9,
                    "url": "https://huggingface.co/TheBloke/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                }
            }
                },
        "4": {
            "name": "Very Powerful",
            "description": "For systems with 64GB+ RAM or 40GB+ VRAM - frontier class",
            "recommended_models": ["deepseek-v3", "llama3.1-70b"],
            "default": "llama3.1-70b",
            "models": {
                "deepseek-v3": {
                    "name": "DeepSeek-V3",
                    "size_gb": 40.0,
                    "url": "https://huggingface.co/TheBloke/DeepSeek-V3-GGUF/resolve/main/deepseek-v3.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 128000
                },
                "llama3.1-70b": {
                    "name": "Llama 3.1 70B Instruct",
                    "size_gb": 38.0,
                    "url": "https://huggingface.co/TheBloke/Llama-3.1-70B-Instruct-GGUF/resolve/main/llama-3.1-70b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                }
            }
        }
    },
    
    "validators": {
        "description": "Tiny models for command validation (<1B params each)",
        "models": {
            "safety": {
                "name": "Safety Validator",
                "description": "Checks for destructive or dangerous commands",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            },
            "logic": {
                "name": "Logic Validator",
                "description": "Verifies command sequence makes sense",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            },
            "efficiency": {
                "name": "Efficiency Validator",
                "description": "Suggests optimizations and faster alternatives",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            }
        }
    },
    
    "alternatives": {
        "description": "Alternative model sources if HuggingFace is unavailable",
        "ollama": {
            "tier1": ["qwen2.5:0.5b"],
            "tier2": ["llama3.2:3b"],
            "tier3": ["phi4:14b"],
            "tier4": ["deepseek-v3", "llama3.1:70b"]
        }
    }
}
