{
    "version": "2.0.0",
    "updated": "2024-12-27",
    "base_url": "https://huggingface.co",
    
    "tiers": {
        "1": {
            "name": "Easy",
            "description": "For systems with <1GB RAM - super lightweight model (NEW)",
            "recommended_models": ["tinyllama-1.1b"],
            "default": "tinyllama-1.1b",
            "models": {
                "tinyllama-1.1b": {
                    "name": "TinyLlama 1.1B Chat",
                    "size_gb": 0.7,
                    "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 2048,
                    "note": "Super lightweight model for minimal systems - NEW Easy tier"
                }
            }
        },
        "2": {
            "name": "Mid",
            "description": "For systems with 1-4GB RAM - balanced performance (formerly Easy tier)",
            "recommended_models": ["qwen2.5-0.5b"],
            "default": "qwen2.5-0.5b",
            "models": {
                "qwen2.5-0.5b": {
                    "name": "Qwen 2.5 0.5B Instruct",
                    "size_gb": 0.4,
                    "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 32768,
                    "note": "Formerly Easy tier - now Mid tier"
                }
            }
        },
        "3": {
            "name": "Hard",
            "description": "For systems with 4-16GB RAM - high performance (formerly Mid tier)",
            "recommended_models": ["llama3.2-3b"],
            "default": "llama3.2-3b",
            "models": {
                "llama3.2-3b": {
                    "name": "Llama 3.2 3B Instruct",
                    "size_gb": 2.0,
                    "url": "https://huggingface.co/TheBloke/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192,
                    "note": "Formerly Mid tier - now Hard tier"
                }
            }
        },
        "4": {
            "name": "Very Powerful",
            "description": "For systems with 16GB+ RAM or 8GB+ VRAM - maximum performance (formerly Hard tier)",
            "recommended_models": ["llama3.1-8b"],
            "default": "llama3.1-8b",
            "models": {
                "llama3.1-8b": {
                    "name": "Llama 3.1 8B Instruct",
                    "size_gb": 4.9,
                    "url": "https://huggingface.co/TheBloke/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                }
            }
        },
        "5": {
            "name": "Very Powerful",
            "description": "For systems with 64GB+ RAM or 40GB+ VRAM - frontier class",
            "recommended_models": ["deepseek-v3", "llama3.1-70b"],
            "default": "llama3.1-70b",
            "models": {
                "deepseek-v3": {
                    "name": "DeepSeek-V3",
                    "size_gb": 40.0,
                    "url": "https://huggingface.co/TheBloke/DeepSeek-V3-GGUF/resolve/main/deepseek-v3.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 128000
                },
                "llama3.1-70b": {
                    "name": "Llama 3.1 70B Instruct",
                    "size_gb": 38.0,
                    "url": "https://huggingface.co/TheBloke/Llama-3.1-70B-Instruct-GGUF/resolve/main/llama-3.1-70b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                }
            }
        }
    },
    
    "validators": {
        "description": "Tiny models for command validation (<1B params each)",
        "models": {
            "safety": {
                "name": "Safety Validator",
                "description": "Checks for destructive or dangerous commands",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            },
            "logic": {
                "name": "Logic Validator",
                "description": "Verifies command sequence makes sense",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            },
            "efficiency": {
                "name": "Efficiency Validator",
                "description": "Suggests optimizations and faster alternatives",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            }
        }
    },
    
    "alternatives": {
        "description": "Alternative model sources if HuggingFace is unavailable",
        "ollama": {
            "tier1": ["tinyllama:1.1b"],
            "tier2": ["qwen2.5:0.5b"],
            "tier3": ["llama3.2:3b"],
            "tier4": ["llama3.1:8b"],
            "tier5": ["deepseek-v3", "llama3.1:70b"]
        }
    }
}
