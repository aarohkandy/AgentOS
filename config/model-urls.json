{
    "version": "1.0.0",
    "updated": "2024-12-20",
    "base_url": "https://huggingface.co",
    
    "tiers": {
        "1": {
            "name": "Lightweight",
            "description": "For systems with <8GB RAM",
            "recommended_models": ["smollm-1.7b", "phi3-mini"],
            "default": "smollm-1.7b",
            "models": {
                "smollm-1.7b": {
                    "name": "SmolLM 1.7B",
                    "size_gb": 1.2,
                    "url": "https://huggingface.co/TheBloke/SmolLM-1.7B-GGUF/resolve/main/smollm-1.7b.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 2048
                },
                "phi3-mini": {
                    "name": "Phi-3 Mini 4K Instruct",
                    "size_gb": 2.4,
                    "url": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf",
                    "sha256": "",
                    "quantization": "Q4",
                    "context_length": 4096
                }
            }
        },
        "2": {
            "name": "Balanced",
            "description": "For systems with 8-16GB RAM",
            "recommended_models": ["qwen2.5-3b", "llama3.2-3b"],
            "default": "qwen2.5-3b",
            "models": {
                "qwen2.5-3b": {
                    "name": "Qwen2.5 3B Instruct",
                    "size_gb": 2.0,
                    "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q4_k_m.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 32768
                },
                "llama3.2-3b": {
                    "name": "Llama 3.2 3B Instruct",
                    "size_gb": 2.0,
                    "url": "https://huggingface.co/TheBloke/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                }
            }
        },
        "3": {
            "name": "Powerful",
            "description": "For systems with >16GB RAM or dedicated GPU",
            "recommended_models": ["qwen2.5-7b", "llama3.1-8b"],
            "default": "qwen2.5-7b",
            "models": {
                "qwen2.5-7b": {
                    "name": "Qwen2.5 7B Instruct",
                    "size_gb": 4.7,
                    "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 32768
                },
                "llama3.1-8b": {
                    "name": "Llama 3.1 8B Instruct",
                    "size_gb": 4.9,
                    "url": "https://huggingface.co/TheBloke/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q4_K_M.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 8192
                },
                "qwen2.5-14b": {
                    "name": "Qwen2.5 14B Instruct",
                    "size_gb": 8.9,
                    "url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-GGUF/resolve/main/qwen2.5-14b-instruct-q4_k_m.gguf",
                    "sha256": "",
                    "quantization": "Q4_K_M",
                    "context_length": 32768
                }
            }
        }
    },
    
    "validators": {
        "description": "Tiny models for command validation (<1B params each)",
        "models": {
            "safety": {
                "name": "Safety Validator",
                "description": "Checks for destructive or dangerous commands",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            },
            "logic": {
                "name": "Logic Validator",
                "description": "Verifies command sequence makes sense",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            },
            "efficiency": {
                "name": "Efficiency Validator",
                "description": "Suggests optimizations and faster alternatives",
                "size_gb": 0.7,
                "url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf",
                "sha256": "",
                "quantization": "Q4_K_M"
            }
        }
    },
    
    "alternatives": {
        "description": "Alternative model sources if HuggingFace is unavailable",
        "ollama": {
            "tier1": ["smollm:1.7b", "phi3:mini"],
            "tier2": ["qwen2.5:3b", "llama3.2:3b"],
            "tier3": ["qwen2.5:7b", "llama3.1:8b"]
        }
    }
}
