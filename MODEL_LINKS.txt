# Direct Model Download Links
# Use these URLs to manually download models if install-models.sh doesn't work

TIER 1 (Easy - <2GB RAM):
TinyLlama 1.1B Chat (~640MB)
https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
Save to: models/tier1/model.gguf

TIER 2 (Mid - 2-8GB RAM):
Qwen 2.5 0.5B Instruct (~400MB)
https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf
Save to: models/tier2/model.gguf

TIER 3 (Hard - 8-16GB RAM):
Llama 3.2 3B Instruct (~2GB)
https://huggingface.co/TheBloke/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q4_K_M.gguf
Save to: models/tier3/model.gguf

TIER 4 (Very Powerful - 16GB+ RAM or 8GB+ VRAM):
Llama 3.1 8B Instruct (~4.9GB)
https://huggingface.co/TheBloke/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q4_K_M.gguf
Save to: models/tier4/model.gguf

TIER 5 (Frontier - 64GB+ RAM or 40GB+ VRAM):
Llama 3.1 70B Instruct (~38GB)
https://huggingface.co/TheBloke/Llama-3.1-70B-Instruct-GGUF/resolve/main/llama-3.1-70b-instruct.Q4_K_M.gguf
Save to: models/tier5/model.gguf

DeepSeek-V3 (~40GB)
https://huggingface.co/TheBloke/DeepSeek-V3-GGUF/resolve/main/deepseek-v3.Q4_K_M.gguf
Save to: models/tier5/deepseek-v3.gguf

VALIDATORS (Optional):
TinyLlama 1.1B for all validators (~700MB each)
https://huggingface.co/TheBloke/TinyLlama-1.1B-GGUF/resolve/main/tinyllama-1.1b.Q4_K_M.gguf
Save to: models/validators/safety.gguf, logic.gguf, efficiency.gguf

QUICK DOWNLOAD COMMANDS:
# Tier 1
wget -O models/tier1/model.gguf "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"

# Tier 2
wget -O models/tier2/model.gguf "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf"

# Tier 3
wget -O models/tier3/model.gguf "https://huggingface.co/TheBloke/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q4_K_M.gguf"

# Tier 4
wget -O models/tier4/model.gguf "https://huggingface.co/TheBloke/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q4_K_M.gguf"

# Tier 5 (70B)
wget -O models/tier5/model.gguf "https://huggingface.co/TheBloke/Llama-3.1-70B-Instruct-GGUF/resolve/main/llama-3.1-70b-instruct.Q4_K_M.gguf"
